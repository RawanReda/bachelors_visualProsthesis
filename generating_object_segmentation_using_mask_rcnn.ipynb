{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0HDLCr5qoRJ"
      },
      "source": [
        "# Mask R-CNN on videos Using pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z2kxYOcqoRN"
      },
      "source": [
        "## Install Matterport Mask-RCNN in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "N9FSlLNsqoRO",
        "outputId": "b95dc4c0-8eaa-4609-c051-fc88e8f352ad"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/53740577/does-any-one-got-attributeerror-str-object-has-no-attribute-decode-whi\n",
        "!pip3 install 'h5py==2.10.0' --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "LSmdHWFOqoRP",
        "outputId": "8a9421c7-405d-447d-8f23-e461e77a92d0"
      },
      "outputs": [],
      "source": [
        "#enforce tensorflow version 1 \n",
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee0quMsRqoRP",
        "outputId": "32cd3911-a238-4617-c28b-b19815ff4265"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN\n",
        "%cd Mask_RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISw_hU7kqoRP"
      },
      "outputs": [],
      "source": [
        "# https://github.com/matterport/Mask_RCNN/issues/1754#issuecomment-776493501\n",
        "\n",
        "with open('mrcnn/model.py') as f:\n",
        "    model_file = f.read()\n",
        "\n",
        "with open('mrcnn/model.py', 'w') as f:\n",
        "    model_file = model_file.replace(\"self.keras_model = self.build(mode=mode, config=config)\",\n",
        "                                    \"self.keras_model = self.build(mode=mode, config=config)\\n        self.keras_model.metrics_tensors = []\")\n",
        "    f.write(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDvY7L4VqoRQ",
        "outputId": "d7ec42d5-16cd-4152-ade0-5e3f71ed9d15"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r requirements.txt\n",
        "!python3 setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTvopat1qoRQ",
        "outputId": "61e8fd71-af0f-4f67-9da1-17583484fa4e"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!make\n",
        "%cd ../../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTpsrAZTqoRR"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fLQbMkvhqoRR",
        "outputId": "3b545841-fce7-44bd-8512-c6a41c03dce0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "# Import COCO config\n",
        "sys.path.append(\"samples/coco/\")  # To find local version\n",
        "import coco\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = \"images\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g98y9a9AqoRS"
      },
      "source": [
        "## Configurations\n",
        "\n",
        "We'll be using a model trained on the MS-COCO dataset. The configurations of this model are in the ```CocoConfig``` class in ```coco.py```.\n",
        "\n",
        "For inferencing, modify the configurations a bit to fit the task. To do so, sub-class the ```CocoConfig``` class and override the attributes you need to change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haRPdHEnqoRS"
      },
      "outputs": [],
      "source": [
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzx-Kg9yWpPk"
      },
      "outputs": [],
      "source": [
        "import colorsys\n",
        "def random_colors(N, bright=True):\n",
        "    \"\"\"\n",
        "    Generate random colors.\n",
        "    To get visually distinct colors, generate them in HSV space then\n",
        "    convert to RGB.\n",
        "    \"\"\"\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTf7tMmTqoRT"
      },
      "outputs": [],
      "source": [
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "colors = random_colors(len(class_names))\n",
        "color_map = dict(zip(class_names, np.array(colors)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQKbh3GhqoRT"
      },
      "source": [
        "## Create Model and Load Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJXofo9pqoRT",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config);\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxO0LlRRqoRU"
      },
      "source": [
        "## Run Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wAwgCW5qoRU",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Load a random image from the images folder\n",
        "file_names = next(os.walk(IMAGE_DIR))[2]\n",
        "image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
        "\n",
        "# Run detection\n",
        "results = model.detect([image], verbose=1)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feRSqNBM1W5M"
      },
      "outputs": [],
      "source": [
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"Apply the given mask to the image.\n",
        "    \"\"\"\n",
        "    for c in range(3):\n",
        "        image[:, :, c] = np.where(mask == 1,\n",
        "                                  image[:, :, c] *\n",
        "                                  (1 - alpha) + alpha * color[c] * 255,\n",
        "                                  image[:, :, c])\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJykFV4N0z7H"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Mask R-CNN\n",
        "Display and Visualization Functions.\n",
        "\n",
        "Copyright (c) 2017 Matterport, Inc.\n",
        "Licensed under the MIT License (see LICENSE for details)\n",
        "Written by Waleed Abdulla\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import itertools\n",
        "import colorsys\n",
        "\n",
        "import numpy as np\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches,  lines\n",
        "from matplotlib.patches import Polygon\n",
        "import IPython.display\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"../\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "\n",
        "\n",
        "############################################################\n",
        "#  Visualization\n",
        "############################################################\n",
        "\n",
        "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n",
        "                   interpolation=None):\n",
        "    \"\"\"Display the given set of images, optionally with titles.\n",
        "    images: list or array of image tensors in HWC format.\n",
        "    titles: optional. A list of titles to display with each image.\n",
        "    cols: number of images per row\n",
        "    cmap: Optional. Color map to use. For example, \"Blues\".\n",
        "    norm: Optional. A Normalize instance to map values to colors.\n",
        "    interpolation: Optional. Image interpolation to use for display.\n",
        "    \"\"\"\n",
        "    titles = titles if titles is not None else [\"\"] * len(images)\n",
        "    rows = len(images) // cols + 1\n",
        "    plt.figure(figsize=(14, 14 * rows // cols))\n",
        "    i = 1\n",
        "    for image, title in zip(images, titles):\n",
        "        plt.subplot(rows, cols, i)\n",
        "        plt.title(title, fontsize=9)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image.astype(np.uint8), cmap=cmap,\n",
        "                   norm=norm, interpolation=interpolation)\n",
        "        i += 1\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def random_colors(N, bright=True):\n",
        "    \"\"\"\n",
        "    Generate random colors.\n",
        "    To get visually distinct colors, generate them in HSV space then\n",
        "    convert to RGB.\n",
        "    \"\"\"\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors\n",
        "\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"Apply the given mask to the image.\n",
        "    \"\"\"\n",
        "    for c in range(3):\n",
        "        image[:, :, c] = np.where(mask == 1,\n",
        "                                  image[:, :, c] *\n",
        "                                  (1 - alpha) + alpha * color[c] * 255,\n",
        "                                  image[:, :, c])\n",
        "    return image\n",
        "\n",
        "\n",
        "# obtaining a black and white image where white represents the objects detected and black is the background\n",
        "def apply_mask_white(image, mask, color, alpha=0.5):\n",
        "    \"\"\"Apply the given mask to the image.\n",
        "    \"\"\"\n",
        "    for c in range(3):\n",
        "        image[:, :, c] = np.where(mask == 1,\n",
        "                                  image[:, :, c] + color[c] * 255,\n",
        "                                  image[:, :, c])\n",
        "    return image\n",
        "\n",
        "# detecting separate instances of all the objects in the image and assigning the same colour to the same object across different frames but identifying the object\n",
        "def display_instances_objects(image, boxes, masks, class_ids, class_names,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=False,\n",
        "                      colors=None, captions=None):\n",
        "  \n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = colors or random_colors(N)\n",
        "\n",
        "    masked_image_full = image.astype(np.uint32).copy()\n",
        "    masks_new=[]\n",
        "\n",
        "    for i in range(N):\n",
        "        color = (1,1,1)\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            # masked_image_full= apply_mask(masked_image_full, mask, color)\n",
        "            masked_image = np.zeros(image.shape, dtype = \"uint8\") \n",
        "            masked_image = apply_mask_white(masked_image, mask, color).clip(0, 255).astype(\"uint8\")\n",
        "            masked_new=grayScaleImg(image, masked_image )\n",
        "            masks_new.append(masked_new)\n",
        "\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "\n",
        "    return masks_new\n",
        "\n",
        "        \n",
        "def display_instances_black(image, boxes, masks, class_ids, class_names,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=False,\n",
        "                      colors=None, captions=None):\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "        auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = colors or random_colors(N)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    ax.set_ylim(height + 10, -10)\n",
        "    ax.set_xlim(-10, width + 10)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    masked_image =np.zeros(image.shape, dtype = \"uint8\")\n",
        "    for i in range(N):\n",
        "        color = (1,1,1)\n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(p)\n",
        "\n",
        "\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = apply_mask_white(masked_image, mask, color)\n",
        "           # masked_image= masked_image.clip(0, 255).astype(\"uint8\")\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 2)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=(0.5,0.5, 0.5))\n",
        "            ax.add_patch(p)\n",
        "    ax.imshow(masked_image.clip(0, 255).astype(\"uint8\"))\n",
        "\n",
        "    if auto_show:\n",
        "        plt.show()\n",
        "    return masked_image.clip(0, 255).astype(\"uint8\")\n",
        "\n",
        "def display_instances(image, boxes, masks, class_ids, class_names,color_map,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=False,\n",
        "                      colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "        auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    c= np.unique(np.array(class_ids))\n",
        "    colors = colors or random_colors(len(c))\n",
        "    dctnry = dict(zip(c, np.array(colors)))\n",
        "    print(c)\n",
        "    print(dctnry)\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    ax.set_ylim(height + 10, -10)\n",
        "    ax.set_xlim(-10, width + 10)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "    for i in range(N):\n",
        "        color = color_map.get(class_names[class_ids[i]]) \n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(p)\n",
        "\n",
        "\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = apply_mask(masked_image, mask, color)\n",
        "\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "            ax.add_patch(p)\n",
        "\n",
        "    ax.imshow(masked_image.astype(np.uint8))\n",
        "\n",
        "    if auto_show:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def display_top_masks(image, mask, class_ids, class_names, limit=4):\n",
        "    \"\"\"Display the given image and the top few class masks.\"\"\"\n",
        "    to_display = []\n",
        "    titles = []\n",
        "    to_display.append(image)\n",
        "    titles.append(\"H x W={}x{}\".format(image.shape[0], image.shape[1]))\n",
        "    # Pick top prominent classes in this image\n",
        "    unique_class_ids = np.unique(class_ids)\n",
        "    mask_area = [np.sum(mask[:, :, np.where(class_ids == i)[0]])\n",
        "                 for i in unique_class_ids]\n",
        "    top_ids = [v[0] for v in sorted(zip(unique_class_ids, mask_area),\n",
        "                                    key=lambda r: r[1], reverse=True) if v[1] > 0]\n",
        "    # Generate images and titles\n",
        "    for i in range(limit):\n",
        "        class_id = top_ids[i] if i < len(top_ids) else -1\n",
        "        # Pull masks of instances belonging to the same class.\n",
        "        m = mask[:, :, np.where(class_ids == class_id)[0]]\n",
        "        m = np.sum(m * np.arange(1, m.shape[-1] + 1), -1)\n",
        "        to_display.append(m)\n",
        "        titles.append(class_names[class_id] if class_id != -1 else \"-\")\n",
        "    display_images(to_display, titles=titles, cols=limit + 1, cmap=\"Blues_r\")\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTbDGhBGXhRy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "image = skimage.io.imread('/content/bed1.jpg')\n",
        "\n",
        "results = model.detect([image], verbose=0)\n",
        "\n",
        "# Visualize results\n",
        "r = results[0]\n",
        "display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, color_map,r['scores'], show_bbox=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdSptJL6A83n"
      },
      "outputs": [],
      "source": [
        "black= display_instances_black(image, r['rois'], r['masks'], r['class_ids'],\n",
        "                               class_names, r['scores'], show_bbox=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al6fbPG8L4aF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "# Create structuring element, dilate and bitwise-and\n",
        "def grayScaleImg(image, black):\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "    dilate = cv2.dilate(black, kernel, iterations=3)\n",
        "    result = cv2.bitwise_and(image, dilate)\n",
        "    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
        "    # Enhance image contrast\n",
        "    gray = cv2.equalizeHist(gray)\n",
        "    plt.imshow(gray, cmap='gray')\n",
        "    return gray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QseOmkpRT1KN"
      },
      "outputs": [],
      "source": [
        "g=grayScaleImg(image, black)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eLfX6EFc1_k"
      },
      "outputs": [],
      "source": [
        "def get_iou(bb1, bb2):\n",
        "\n",
        "    y11, x11, y12, x12 = bb1\n",
        "    y21, x21, y22, x22 = bb2\n",
        "    assert x11 < x12\n",
        "    assert y11< y12 \n",
        "    assert x21 < x22 \n",
        "    assert y21< y22 \n",
        "\n",
        "    # determine the coordinates of the intersection rectangle\n",
        "    x_left = max(x11, x21 )\n",
        "    y_top = max(y11, y21 )\n",
        "    x_right = min(x12, x22)\n",
        "    y_bottom = min(y12, y22)\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "    print(x_right < x_left)\n",
        "    # The intersection of two axis-aligned bounding boxes is always an\n",
        "    # axis-aligned bounding box\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "    # compute the area of both AABBs\n",
        "    bb1_area = (x12 - x11 ) * (y12 - y11)\n",
        "    bb2_area = ( x22  - x21) * (y22 - y21)\n",
        "\n",
        "    # compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the interesection area\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J4zYH7rsPcp"
      },
      "outputs": [],
      "source": [
        "display_instances_objects(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'], show_bbox=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i01d54ljGZXK"
      },
      "outputs": [],
      "source": [
        "display_images([display_instances_objects(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'], show_bbox=False)][0], cmap= 'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKlzfo_XrxWe"
      },
      "outputs": [],
      "source": [
        "m=display_instances_objects(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'], show_bbox=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOdK_Dp1xxes"
      },
      "outputs": [],
      "source": [
        "plt.imshow(m[1].astype(np.uint8), cmap= 'gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1HTjLY65gJQ"
      },
      "outputs": [],
      "source": [
        "def image_resize(images, rois, desired_size=32):\n",
        "        res=[]\n",
        "        for i in range(0, len(images)):\n",
        "                im = images[i]\n",
        "                k= r['rois'][i]\n",
        "                im= m[i][k[0]:k[2], k[1]:k[3]]\n",
        "                old_size = im.shape[:2] # old_size is in (height, width) format\n",
        "\n",
        "                ratio = float(desired_size)/max(old_size)\n",
        "                new_size = tuple([int(x*ratio) for x in old_size])\n",
        "\n",
        "                # new_size should be in (width, height) format\n",
        "\n",
        "                im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "\n",
        "                delta_w = desired_size - new_size[1]\n",
        "                delta_h = desired_size - new_size[0]\n",
        "                top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "\n",
        "                color = [0, 0, 0]\n",
        "                new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                    value=color)\n",
        "                res.append(new_im)\n",
        "        return res\n",
        "              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HCi4UxHe-uW"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"home_imagesn\")\n",
        "for i in range(0, len(m)): \n",
        "  plt.imshow(m[i], cmap= 'gray')\n",
        "  plt.axis('off')\n",
        "  cv2.imwrite(\"home_imagesn/object\"+str(i)+\".png\", m[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fre_f61r5mgz"
      },
      "outputs": [],
      "source": [
        "cropped= image_resize(m, r['rois'])\n",
        "os.makedirs(\"home_images_croppednew1\")\n",
        "for i in range(0, len(m)): \n",
        "  plt.imshow(cropped[i], cmap= 'gray')\n",
        "  print(cropped[i].shape)\n",
        "  plt.axis('off')\n",
        "  #plt.savefig(\"home_images_croppedn/object\"+str(i)+\".png\", bbox_inches='tight',pad_inches = 0)\n",
        "  cv2.imwrite(\"home_images_croppednew1/object\"+str(i)+\".png\", cropped[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMyf4_dNRM0D"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "image = Image.open(\"/content/bed1.jpg\")\n",
        "image = image.resize((3072,3072),Image.ANTIALIAS)\n",
        "image.save(fp=\"newimage.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generating Images and Videos from the implemented code: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZXDobjqgOdJ"
      },
      "outputs": [],
      "source": [
        "!zip -r imgsLocn.zip home_images1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI_t_gu3YV3m"
      },
      "outputs": [],
      "source": [
        "!zip -r imgsCroppednew.zip home_images_croppednew1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kg8Ap7PRry-H"
      },
      "outputs": [],
      "source": [
        "display_top_masks(image, r['masks'], r['class_ids'], class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FkeLfFFf-Ps"
      },
      "outputs": [],
      "source": [
        "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDi9lYdzmX42"
      },
      "outputs": [],
      "source": [
        "def get_color_dict():\n",
        "  all_colors = visualize.random_colors(100)\n",
        "  color_dict = {}\n",
        "  i = 0\n",
        "  for c in class_names:\n",
        "    if not c in color_dict:\n",
        "      color_dict[c] = all_colors[i]\n",
        "      i = i+1\n",
        "  color_dict[\"background\"] = (0,0,0)\n",
        "  return color_dict\n",
        "\n",
        "COLOR_MAP = get_color_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr4RjnX5m2kK"
      },
      "outputs": [],
      "source": [
        "def label_to_color_image(labels):\n",
        "  # Adds color defined by the dataset colormap to the label.\n",
        "  h,w = labels.shape\n",
        "  img = np.zeros([h,w,3])\n",
        "  img = np.zeros((h,w),dtype=(float,3))\n",
        "  for i in range(h):\n",
        "    for j in range(w):\n",
        "      img[i][j] = np.array(COLOR_MAP[CLASS_NAMES_MASKRCNN[labels[i][j]]])        \n",
        "  img = img*255\n",
        "  return img.astype(np.uint8)\n",
        "\n",
        "def combine_masks(img, result):\n",
        "  boxes = result['rois']\n",
        "  masks = result['masks']\n",
        "  class_ids = result['class_ids']\n",
        "  \n",
        "  N = boxes.shape[0]\n",
        "  h,w,c = img.shape\n",
        "  seg_map = np.zeros((h,w))\n",
        "  for i in range(N):\n",
        "    mask = masks[:, :, i]\n",
        "    mask = mask.astype(np.uint8)\n",
        "    seg_map = seg_map + mask*class_ids[i]\n",
        "  \n",
        "  return seg_map.astype(np.uint8)\n",
        "\n",
        "def merge_images(foreground, background, alpha=0.3):\n",
        "  out_img = np.zeros(background.shape,dtype=background.dtype)\n",
        "  out_img[:,:,:] = (alpha * background[:,:,:]) + ((1-alpha) * foreground[:,:,:])\n",
        "  return out_img\n",
        "\n",
        "def get_masked_image1(image, result):\n",
        "  \"\"\"\n",
        "  Applies masks from the results to the given image\n",
        "  \n",
        "  \"\"\"\n",
        "  boxes = result['rois']\n",
        "  masks = result['masks']\n",
        "  \n",
        "  N = boxes.shape[0]\n",
        "  if not N:\n",
        "    print(\"\\n*** No instances to display *** \\n\")\n",
        "\n",
        "  colors = visualize.random_colors(N)\n",
        "  masked_image =  masked_image =np.zeros(image.shape, dtype = \"uint8\")\n",
        "\n",
        "\n",
        "  for i in range(N):\n",
        "      color = (1,1,1)\n",
        "\n",
        "      # Mask\n",
        "      mask = masks[:, :, i]\n",
        "      \n",
        "      masked_image = visualize.apply_mask(masked_image, mask, color)\n",
        "  return masked_image.astype(np.uint8)\n",
        "\n",
        "class Object:\n",
        "  def __init__(self, rois, color):\n",
        "    self.rois = rois\n",
        "    self.color = color\n",
        "\n",
        "def get_color(result, prevFrame):\n",
        "  colors=[]\n",
        "  temp_colors=random_colors(len(result['class_ids']))\n",
        "  for i in range(len(result['class_ids'])):\n",
        "    curr= result['class_ids'][i]\n",
        "    color= temp_colors[i]\n",
        "    if curr in prevFrame:\n",
        "          if len(prevFrame[curr])!=0:\n",
        "            iou=0\n",
        "            for obj in prevFrame[curr]:\n",
        "              rois=obj.rois\n",
        "              temp= get_iou(rois, result['rois'][i])\n",
        "              if temp>=0.3 and temp>iou:\n",
        "                color= obj.color\n",
        "    colors.append(color)  \n",
        "    print(\"clrs\",colors)  \n",
        "  return colors\n",
        "\n",
        "\n",
        "def get_masked_image_maintainColor_GRAY(image, result, prevFrame, flag):\n",
        "  boxes = result['rois']\n",
        "  masks = result['masks']\n",
        "  \n",
        "  N = boxes.shape[0]\n",
        "  if not N:\n",
        "    print(\"\\n*** No instances to display *** \\n\")\n",
        "\n",
        "  colors = get_color(result, prevFrame)\n",
        "  masked_image = image.astype(np.uint32).copy()\n",
        "  print(\"ccc\",colors)\n",
        "  keys = result['class_ids']\n",
        "  # newFrame ={key: [] for key in keys}\n",
        "  newFrame= prevFrame\n",
        "  for i in range(N):\n",
        "      color = colors[i]\n",
        "      if result['class_ids'][i] in newFrame:\n",
        "          newFrame[result['class_ids'][i]].append(Object(result['rois'][i], color))      \n",
        "      else:\n",
        "         newFrame[result['class_ids'][i]]= [Object(result['rois'][i], color)]\n",
        "      # Mask\n",
        "      mask = masks[:, :, i]\n",
        "      #masked_image.clip(0, 255).astype(\"uint8\")\n",
        "    \n",
        "  black= display_instances_black(image, result['rois'], result['masks'], result['class_ids'], \n",
        "                                class_names, result['scores'], show_bbox=False)\n",
        "  if flag==1:    \n",
        "     return newFrame, black.astype(np.uint8)\n",
        "      \n",
        "  masked=grayScaleImg(image, black)\n",
        "  return newFrame, masked.astype(np.uint8)\n",
        "      \n",
        " \n",
        "\n",
        "\n",
        "def get_masked_image_maintainColor(image, result, prevFrame):\n",
        "  \"\"\"\n",
        "  Applies masks from the results to the given image\n",
        "\n",
        "  first, check if the prevFrame contains the same object in the current frame ['key':[<result, color>]]\n",
        "\n",
        "  there can be several objects of the same class \n",
        "\n",
        "  for each object of the same class calculate the iou\n",
        "\n",
        "  assign the same colour to the curr object\n",
        "\n",
        "  update the prevFrame by creating a new frame dictionary containing each object's result and color \n",
        "  \n",
        "  \"\"\"\n",
        "  boxes = result['rois']\n",
        "  masks = result['masks']\n",
        "  \n",
        "  N = boxes.shape[0]\n",
        "  if not N:\n",
        "    print(\"\\n*** No instances to display *** \\n\")\n",
        "\n",
        "  colors = get_color(result, prevFrame)\n",
        "  masked_image = image.astype(np.uint32).copy()\n",
        "  print(\"ccc\",colors)\n",
        "  keys = result['class_ids']\n",
        "  # newFrame ={key: [] for key in keys}\n",
        "  newFrame= prevFrame\n",
        "  for i in range(N):\n",
        "      color = colors[i]\n",
        "      if result['class_ids'][i] in newFrame:\n",
        "          newFrame[result['class_ids'][i]].append(Object(result['rois'][i], color))      \n",
        "      else:\n",
        "         newFrame[result['class_ids'][i]]= [Object(result['rois'][i], color)]\n",
        "      # Mask\n",
        "      mask = masks[:, :, i]\n",
        "      masked_image = visualize.apply_mask(masked_image, mask, color)\n",
        "  return newFrame, masked_image.astype(np.uint8)\n",
        "\n",
        "def get_masked_image(image, result):\n",
        "  \"\"\"\n",
        "  Applies masks from the results to the given image\n",
        "  \n",
        "  \"\"\"\n",
        "  boxes = result['rois']\n",
        "  masks = result['masks']\n",
        "  \n",
        "  N = boxes.shape[0]\n",
        "  if not N:\n",
        "    print(\"\\n*** No instances to display *** \\n\")\n",
        "\n",
        "  colors = visualize.random_colors(N)\n",
        "  masked_image = image.astype(np.uint32).copy()\n",
        "\n",
        "  for i in range(N):\n",
        "      color = colors[i]\n",
        "\n",
        "      # Mask\n",
        "      mask = masks[:, :, i]\n",
        "      masked_image = visualize.apply_mask(masked_image, mask, color)\n",
        "  return masked_image.astype(np.uint8)\n",
        "\n",
        "\n",
        "def get_coloured_mask(image, boxes, masks, class_ids, class_names,color_map,\n",
        "                      scores=None, title=\"\",\n",
        "                      figsize=(16, 16), ax=None,\n",
        "                      show_mask=True, show_bbox=False,\n",
        "                      colors=None, captions=None):\n",
        "    \"\"\"\n",
        "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
        "    masks: [height, width, num_instances]\n",
        "    class_ids: [num_instances]\n",
        "    class_names: list of class names of the dataset\n",
        "    scores: (optional) confidence scores for each box\n",
        "    title: (optional) Figure title\n",
        "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
        "    figsize: (optional) the size of the image\n",
        "    colors: (optional) An array or colors to use with each object\n",
        "    captions: (optional) A list of strings to use as captions for each object\n",
        "    \"\"\"\n",
        "\n",
        "    # Number of instances\n",
        "    N = boxes.shape[0]\n",
        "    if not N:\n",
        "        print(\"\\n*** No instances to display *** \\n\")\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
        "\n",
        "    # If no axis is passed, create one and automatically call show()\n",
        "    auto_show = False\n",
        "    if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "        auto_show = True\n",
        "\n",
        "    # Generate random colors\n",
        "    c= np.unique(np.array(class_ids))\n",
        "    colors = colors or random_colors(len(c))\n",
        "    dctnry = dict(zip(c, np.array(colors)))\n",
        "    print(c)\n",
        "    print(dctnry)\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    ax.set_ylim(height + 10, -10)\n",
        "    ax.set_xlim(-10, width + 10)\n",
        "    ax.axis('off')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "    for i in range(N):\n",
        "        color = color_map.get(class_names[class_ids[i]]) \n",
        "\n",
        "        # Bounding box\n",
        "        if not np.any(boxes[i]):\n",
        "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
        "            continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        if show_bbox:\n",
        "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
        "                                alpha=0.7, linestyle=\"dashed\",\n",
        "                                edgecolor=color, facecolor='none')\n",
        "            ax.add_patch(p)\n",
        "\n",
        "\n",
        "\n",
        "        # Mask\n",
        "        mask = masks[:, :, i]\n",
        "        if show_mask:\n",
        "            masked_image = apply_mask(masked_image, mask, color)\n",
        "\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        padded_mask = np.zeros(\n",
        "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
        "        padded_mask[1:-1, 1:-1] = mask\n",
        "        contours = find_contours(padded_mask, 0.5)\n",
        "        for verts in contours:\n",
        "            # Subtract the padding and flip (y, x) to (x, y)\n",
        "            verts = np.fliplr(verts) - 1\n",
        "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "            ax.add_patch(p)\n",
        "    return masked_image.astype(np.uint8)\n",
        " \n",
        "\n",
        "\n",
        "def print_fps(video):\n",
        "  # Find OpenCV version\n",
        "  (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "  if int(major_ver)  < 3 :\n",
        "      fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "      print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "  else :\n",
        "      fps = video.get(cv2.CAP_PROP_FPS)\n",
        "      print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "\n",
        "\n",
        "def make_video(outvid, images=None, fps=30, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        " \n",
        "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
        "    By default, the video will have the size of the first image.\n",
        "    It will resize every image to this size before adding them to the video.\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbhN73wXozdC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "VIDEO_DIR = os.path.join(\"\", \"videos\")\n",
        "VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"bathroom_contrast\")\n",
        "\n",
        "try:\n",
        "    if not os.path.exists(VIDEO_SAVE_DIR):\n",
        "        os.makedirs(VIDEO_SAVE_DIR)\n",
        "except OSError:\n",
        "    print ('Error: Creating directory of data')\n",
        "\n",
        "os.chdir('./videos')\n",
        "\n",
        "from google.colab import files\n",
        "uploads = files.upload()\n",
        "\n",
        "os.chdir('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BRiHMuBnFLV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# number of images to be processed at once\n",
        "batch_size = 1\n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = batch_size\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(\n",
        "    mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
        ")\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "CLASS_NAMES_MASKRCNN = ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "                 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "                 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "                 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "                 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "                 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "                 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "                 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "                 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "                 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "                 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "                 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "                 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "                 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "                 'teddy bear', 'hair drier', 'toothbrush']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHARsD8enLIk"
      },
      "outputs": [],
      "source": [
        "for upload in uploads.keys():\n",
        "  capture = cv2.VideoCapture(os.path.join(VIDEO_DIR, upload))\n",
        "  \n",
        "  print_fps(capture)\n",
        "  \n",
        "  try:\n",
        "      if not os.path.exists(VIDEO_SAVE_DIR):\n",
        "          os.makedirs(VIDEO_SAVE_DIR)\n",
        "  except OSError:\n",
        "      print ('Error: Creating directory of data')\n",
        "  frames = []\n",
        "  frame_count = 0\n",
        "  keys = CLASS_NAMES_MASKRCNN\n",
        "  prevFrameD ={key: [] for key in keys}\n",
        "  while True:\n",
        "      ret, frame = capture.read()\n",
        "      # Bail out when the video file ends\n",
        "      if not ret:\n",
        "          break\n",
        "          \n",
        "      # Save each frame of the video to a list\n",
        "      frame_count += 1\n",
        "      frames.append(frame)\n",
        "      print('frame_count :{0}'.format(frame_count))\n",
        "      if len(frames) == batch_size:\n",
        "          results = model.detect(frames, verbose=0)\n",
        "          print('Predicted')\n",
        "          for i, item in enumerate(zip(frames, results)):\n",
        "              frame = item[0]\n",
        "              r = item[1]\n",
        "              #seg_map = combine_masks(frame, r)\n",
        "              #seg_image = label_to_color_image(seg_map)\n",
        "              #frame = merge_images(seg_image, frame)\n",
        "              #frame= get_coloured_mask(frame,r['rois'], r['masks'], r['class_ids'], \n",
        "              #                        class_names, color_map,r['scores'], show_bbox=False)\n",
        "              #frame = get_masked_image(frame, r)\n",
        "\n",
        "              ##maintains colour of object instances:\n",
        "              #prevFrameD, frame= get_masked_image_maintainColor(frame, r,  prevFrameD)\n",
        "\n",
        "              ##get greyScale object instead of the mask and makes it greyscale :)\n",
        "              prevFrameD, frame= get_masked_image_maintainColor_GRAY(frame, r,  prevFrameD, 0)\n",
        "\n",
        "              # prevFrameD, frame= get_masked_image_maintainColor_GRAY(frame, r,  prevFrameD, 0)\n",
        "\n",
        "\n",
        "\n",
        "              name = '{0}.jpg'.format(frame_count + i - batch_size)\n",
        "              name = os.path.join(VIDEO_SAVE_DIR, name)\n",
        "              cv2.imwrite(name, frame)\n",
        "          # Clear the frames array to start the next batch\n",
        "          frames = []\n",
        "\n",
        "  capture.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKo0vXUFnRbu"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "images = list(glob.iglob(os.path.join(VIDEO_SAVE_DIR, '*.*')))\n",
        "# Sort the images by integer index\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "\n",
        "outvid = os.path.join(VIDEO_DIR, \"bathroom-mask.mp4\")\n",
        "make_video(outvid, images, fps=20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "7de87cdb277b6f106f9c16ebb52fd0bf60e72bb13bb80caa36e06be0a541ffdf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
